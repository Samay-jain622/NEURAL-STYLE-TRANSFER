{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLtSvfnnhvxp+lRTQ0djn9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samay-jain622/NEURAL-STYLE-TRANSFER/blob/main/app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mb9d5N7jT3mH"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG19, ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input as preprocess_vgg\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_resnet\n",
        "import cv2\n",
        "\n",
        "# Function to compute Gram matrix\n",
        "def gram_matrix(input_tensor):\n",
        "    result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n",
        "    input_shape = tf.shape(input_tensor)\n",
        "    num_locations = tf.cast(input_shape[1] * input_shape[2], tf.float32)\n",
        "    return result / num_locations\n",
        "\n",
        "# Function to load VGG19 model and define layers\n",
        "def load_vgg():\n",
        "    vgg = VGG19(include_top=False, weights='imagenet')\n",
        "    content_layers = ['block4_conv2']\n",
        "    style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "    vgg.trainable = False\n",
        "    content_outputs = [vgg.get_layer(layer).output for layer in content_layers]\n",
        "    style_outputs = [vgg.get_layer(layer).output for layer in style_layers]\n",
        "    model_outputs = content_outputs + style_outputs\n",
        "    return Model(vgg.input, model_outputs)\n",
        "\n",
        "# Function to load ResNet50 model and define layers\n",
        "def load_resnet():\n",
        "    resnet = ResNet50(include_top=False, weights='imagenet')\n",
        "    content_layers = ['conv4_block6_out']\n",
        "    style_layers = ['conv1_conv', 'conv2_block3_out', 'conv3_block4_out', 'conv4_block6_out', 'conv5_block3_out']\n",
        "    resnet.trainable = False\n",
        "    content_outputs = [resnet.get_layer(layer).output for layer in content_layers]\n",
        "    style_outputs = [resnet.get_layer(layer).output for layer in style_layers]\n",
        "    model_outputs = content_outputs + style_outputs\n",
        "    return Model(resnet.input, model_outputs)\n",
        "\n",
        "# Streamlit UI\n",
        "def main():\n",
        "    st.title('Neural Style Transfer')\n",
        "\n",
        "    model_option = st.selectbox('Choose model for style transfer', ('VGG19', 'ResNet50'))\n",
        "\n",
        "    content_file = st.file_uploader('Upload content image', type=['jpg', 'png', 'jpeg'])\n",
        "    style_file = st.file_uploader('Upload style image', type=['jpg', 'png', 'jpeg'])\n",
        "    button_tostyle = st.button('Stylize Image')\n",
        "\n",
        "    if content_file and style_file and button_tostyle:\n",
        "        content_image = cv2.imdecode(np.frombuffer(content_file.read(), np.uint8), cv2.IMREAD_COLOR)\n",
        "        style_image = cv2.imdecode(np.frombuffer(style_file.read(), np.uint8), cv2.IMREAD_COLOR)\n",
        "\n",
        "        if model_option == 'VGG19':\n",
        "            # Convert BGR to RGB for VGG19\n",
        "            content_image = cv2.cvtColor(content_image, cv2.COLOR_BGR2RGB)\n",
        "            style_image = cv2.cvtColor(style_image, cv2.COLOR_BGR2RGB)\n",
        "            preprocess = preprocess_vgg\n",
        "            model = load_vgg()\n",
        "            style_weight = 1e-2\n",
        "            content_weight = 1e-4\n",
        "        else:\n",
        "            # ResNet50 expects BGR format, no conversion needed\n",
        "            preprocess = preprocess_resnet\n",
        "            model = load_resnet()\n",
        "            style_weight = 1\n",
        "            content_weight = 1e-2\n",
        "\n",
        "        content_image = cv2.resize(content_image, (224, 224))\n",
        "        style_image = cv2.resize(style_image, (224, 224))\n",
        "        content_image = tf.image.convert_image_dtype(content_image, tf.float32)\n",
        "        style_image = tf.image.convert_image_dtype(style_image, tf.float32)\n",
        "\n",
        "        content_image_processed = preprocess(tf.expand_dims(content_image, axis=0))\n",
        "        style_image_processed = preprocess(tf.expand_dims(style_image, axis=0))\n",
        "\n",
        "        content_target = model(content_image_processed)[0]\n",
        "        style_target = [gram_matrix(output) for output in model(style_image_processed)[1:]]\n",
        "\n",
        "        opt = tf.keras.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)\n",
        "\n",
        "        def loss_object(style_outputs, content_outputs, style_target, content_target):\n",
        "            content_loss = tf.reduce_mean(tf.square(content_outputs - content_target))\n",
        "            style_loss = tf.add_n([tf.reduce_mean(tf.square(gram_matrix(output) - target)) for output, target in zip(style_outputs, style_target)])\n",
        "            total_loss = content_weight * content_loss + style_weight * style_loss\n",
        "            return total_loss\n",
        "\n",
        "        @tf.function\n",
        "        def train_step(image):\n",
        "            with tf.GradientTape() as tape:\n",
        "                outputs = model(image)\n",
        "                loss = loss_object(outputs[1:], outputs[0], style_target, content_target)\n",
        "            gradient = tape.gradient(loss, image)\n",
        "            opt.apply_gradients([(gradient, image)])\n",
        "            image.assign(tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0))\n",
        "            return loss\n",
        "\n",
        "        Epochs = 1000\n",
        "        stylized_image = tf.Variable(content_image_processed, dtype=tf.float32)\n",
        "\n",
        "        for epoch in range(Epochs):\n",
        "            loss = train_step(stylized_image)\n",
        "            if epoch % 100 == 0:\n",
        "                st.write(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
        "\n",
        "        # Convert back to numpy array for display\n",
        "        stylized_image_np = np.squeeze(stylized_image.numpy())\n",
        "        stylized_image_np = np.clip(stylized_image_np, 0, 1)  # Clip values to valid range\n",
        "\n",
        "        # Convert to RGB if needed (for ResNet50 output)\n",
        "        if model_option == 'ResNet50':\n",
        "            stylized_image_np = cv2.cvtColor((stylized_image_np * 255).astype(np.uint8), cv2.COLOR_BGR2RGB)\n",
        "        else:\n",
        "            stylized_image_np = (stylized_image_np * 255).astype(np.uint8)\n",
        "\n",
        "        st.image(stylized_image_np, caption='Stylized Image', use_column_width=True)\n",
        "\n",
        "    else:\n",
        "        st.write('Upload content and style images to begin.')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ]
}